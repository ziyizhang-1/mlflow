
  

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>mlflow.spark &mdash; MLflow 1.1.0 documentation</title>
  
   
  <link rel="canonical" href="https://www.mlflow.org/docs/latest/python_api/mlflow.spark.html">
  
  
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
    

    

  
    
        <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
        new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
        j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
        'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
        })(window,document,'script','dataLayer','GTM-WXWDBL');</script>
      

  

  
  
    

  

  
  
    <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600" rel="stylesheet">
    <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
    
    <link rel="stylesheet" href="../_static/css/algolia.css" type="text/css" />
    
  
        <link rel="index" title="Index"
              href="../genindex.html"/>
        <link rel="search" title="Search" href="../search.html"/>
    <link rel="top" title="MLflow 1.1.0 documentation" href="../index.html"/>
        <link rel="up" title="Python API" href="index.html"/>
        <link rel="next" title="mlflow.tensorflow" href="/mlflow.tensorflow.html"/>
        <link rel="prev" title="mlflow.sklearn" href="/mlflow.sklearn.html"/> 

  
  <script src="../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav" role="document">

  

  
  <nav class="wy-nav-top header" role="navigation" aria-label="top navigation">
    <ul>
  <li class="menu-toggle">
    <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
    <a href="../index.html" class="wy-nav-top-logo"><img src="../_static/MLflow-logo-final-black.png" alt="MLFlow" /></a> <span class="version">1.1.0</span>
  </li>
</ul>
  </nav>
  <page>
    

    <nav data-toggle="wy-nav-shift" class="wy-nav-side relative">
      <div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    
<div role="search">
  
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
  <input type="text" name="q" placeholder="Search" />
  <input type="hidden" name="check_keywords" value="yes" />
  <input type="hidden" name="area" value="default" />
  </form>
  
</div>


    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home"><img src="../_static/icons/nav-home.svg"> MLflow</a>
    

    
      

      
        <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../quickstart.html">Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tutorial.html">Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../concepts.html">Concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../tracking.html">MLflow Tracking</a></li>
<li class="toctree-l1"><a class="reference internal" href="../projects.html">MLflow Projects</a></li>
<li class="toctree-l1"><a class="reference internal" href="../models.html">MLflow Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../cli.html">Command-Line Interface</a></li>
<li class="toctree-l1"><a class="reference internal" href="../search-syntax.html">Search</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Python API</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="mlflow.html">mlflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.azureml.html">mlflow.azureml</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.entities.html">mlflow.entities</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.h2o.html">mlflow.h2o</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.keras.html">mlflow.keras</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.mleap.html">mlflow.mleap</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.models.html">mlflow.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.onnx.html">mlflow.onnx</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.projects.html">mlflow.projects</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pyfunc.html">mlflow.pyfunc</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.pytorch.html">mlflow.pytorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sagemaker.html">mlflow.sagemaker</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.sklearn.html">mlflow.sklearn</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">mlflow.spark</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.tensorflow.html">mlflow.tensorflow</a></li>
<li class="toctree-l2"><a class="reference internal" href="mlflow.tracking.html">mlflow.tracking</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../R-api.html">R API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../java_api/index.html">Java API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rest-api.html">REST API</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    

    <p>
      <a id='feedbacklink' href="https://github.com/mlflow/mlflow/blob/master/CONTRIBUTING.rst" target="_blank">Contribute</a>
    </p>
  </div>
</div>
    </nav>

    <main class="wy-grid-for-nav">
      <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
        <div class="wy-nav-content">
          <div class="rst-content">
            










<div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="index.html">Python API</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>mlflow.spark</li>
    
    
    <li class="wy-breadcrumbs-aside">
      <a href="https://github.com/mlflow/mlflow/blob/master/docs/source/python_api/mlflow.spark.rst" class="fa fa-github"> Edit on GitHub</a>
    </li>
    
  </ul>
</div>
            <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
              <div itemprop="articleBody">
                
  <div class="section" id="module-mlflow.spark">
<span id="mlflow-spark"></span><h1>mlflow.spark<a class="headerlink" href="#module-mlflow.spark" title="Permalink to this headline"> </a></h1>
<p>The <code class="docutils literal notranslate"><span class="pre">mlflow.spark</span></code> module provides an API for logging and loading Spark MLlib models. This module
exports Spark MLlib models with the following flavors:</p>
<dl class="docutils">
<dt>Spark MLlib (native) format</dt>
<dd>Allows models to be loaded as Spark Transformers for scoring in a Spark session.
Models with this flavor can be loaded as PySpark PipelineModel objects in Python.
This is the main flavor and is always produced.</dd>
<dt><a class="reference internal" href="mlflow.pyfunc.html#module-mlflow.pyfunc" title="mlflow.pyfunc"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mlflow.pyfunc</span></code></a></dt>
<dd>Supports deployment outside of Spark by instantiating a SparkContext and reading
input data as a Spark DataFrame prior to scoring. Also supports deployment in Spark
as a Spark UDF. Models with this flavor can be loaded as Python functions
for performing inference. This flavor is always produced.</dd>
<dt><a class="reference internal" href="mlflow.mleap.html#module-mlflow.mleap" title="mlflow.mleap"><code class="xref py py-mod docutils literal notranslate"><span class="pre">mlflow.mleap</span></code></a></dt>
<dd>Enables high-performance deployment outside of Spark by leveraging MLeap’s
custom dataframe and pipeline representations. Models with this flavor <em>cannot</em> be loaded
back as Python objects. Rather, they must be deserialized in Java using the
<code class="docutils literal notranslate"><span class="pre">mlflow/java</span></code> package. This flavor is produced only if you specify
MLeap-compatible arguments.</dd>
</dl>
<dl class="function">
<dt id="mlflow.spark.get_default_conda_env">
<code class="descclassname">mlflow.spark.</code><code class="descname">get_default_conda_env</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#mlflow.spark.get_default_conda_env" title="Permalink to this definition"> </a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Returns:</th><td class="field-body">The default Conda environment for MLflow Models produced by calls to
<a class="reference internal" href="#mlflow.spark.save_model" title="mlflow.spark.save_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">save_model()</span></code></a> and <a class="reference internal" href="#mlflow.spark.log_model" title="mlflow.spark.log_model"><code class="xref py py-func docutils literal notranslate"><span class="pre">log_model()</span></code></a>.</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="mlflow.spark.load_model">
<code class="descclassname">mlflow.spark.</code><code class="descname">load_model</code><span class="sig-paren">(</span><em>model_uri</em>, <em>dfs_tmpdir=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mlflow.spark.load_model" title="Permalink to this definition"> </a></dt>
<dd><p>Load the Spark MLlib model from the path.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>model_uri</strong> – <p>The location, in URI format, of the MLflow model, for example:</p>
<ul>
<li><code class="docutils literal notranslate"><span class="pre">/Users/me/path/to/local/model</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">relative/path/to/local/model</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">s3://my_bucket/path/to/model</span></code></li>
<li><code class="docutils literal notranslate"><span class="pre">runs:/&lt;mlflow_run_id&gt;/run-relative/path/to/model</span></code></li>
</ul>
<p>For more information about supported URI schemes, see
<a class="reference external" href="https://www.mlflow.org/docs/latest/tracking.html#artifact-locations">Referencing Artifacts</a>.</p>
</li>
<li><strong>dfs_tmpdir</strong> – Temporary directory path on Distributed (Hadoop) File System (DFS) or local
filesystem if running in local mode. The model is loaded from this
destination. Defaults to <code class="docutils literal notranslate"><span class="pre">/tmp/mlflow</span></code>.</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">pyspark.ml.pipeline.PipelineModel</p>
</td>
</tr>
</tbody>
</table>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mlflow</span> <span class="k">import</span> <span class="n">spark</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;spark-model&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Prepare test documents, which are unlabeled (id, text) tuples.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">test</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
<span class="gp">... </span>  <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="s2">&quot;spark i j k&quot;</span><span class="p">),</span>
<span class="gp">... </span>  <span class="p">(</span><span class="mi">5</span><span class="p">,</span> <span class="s2">&quot;l m n&quot;</span><span class="p">),</span>
<span class="gp">... </span>  <span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="s2">&quot;spark hadoop spark&quot;</span><span class="p">),</span>
<span class="gp">... </span>  <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="s2">&quot;apache hadoop&quot;</span><span class="p">)],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span> <span class="c1"># Make predictions on test documents.</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">prediction</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mlflow.spark.log_model">
<code class="descclassname">mlflow.spark.</code><code class="descname">log_model</code><span class="sig-paren">(</span><em>spark_model</em>, <em>artifact_path</em>, <em>conda_env=None</em>, <em>dfs_tmpdir=None</em>, <em>sample_input=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mlflow.spark.log_model" title="Permalink to this definition"> </a></dt>
<dd><p>Log a Spark MLlib model as an MLflow artifact for the current run. This uses the
MLlib persistence format and produces an MLflow Model with the Spark flavor.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>spark_model</strong> – Spark model to be saved - MLFlow can only save descendants of
pyspark.ml.Model which implement MLReadable and MLWritable.</li>
<li><strong>artifact_path</strong> – Run relative artifact path.</li>
<li><strong>conda_env</strong> – <p>Either a dictionary representation of a Conda environment or the path to a
Conda environment yaml file. If provided, this decribes the environment
this model should be run in. At minimum, it should specify the dependencies
contained in <a class="reference internal" href="#mlflow.spark.get_default_conda_env" title="mlflow.spark.get_default_conda_env"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_default_conda_env()</span></code></a>. If <cite>None</cite>, the default
<a class="reference internal" href="#mlflow.spark.get_default_conda_env" title="mlflow.spark.get_default_conda_env"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_default_conda_env()</span></code></a> environment is added to the model.
The following is an <em>example</em> dictionary representation of a Conda
environment:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;mlflow-env&#39;</span><span class="p">,</span>
    <span class="s1">&#39;channels&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;defaults&#39;</span><span class="p">],</span>
    <span class="s1">&#39;dependencies&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;python=3.7.0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pyspark=2.3.0&#39;</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><strong>dfs_tmpdir</strong> – Temporary directory path on Distributed (Hadoop) File System (DFS) or local
filesystem if running in local mode. The model is written in this
destination and then copied into the model’s artifact directory. This is
necessary as Spark ML models read from and write to DFS if running on a
cluster. If this operation completes successfully, all temporary files
created on the DFS are removed. Defaults to <code class="docutils literal notranslate"><span class="pre">/tmp/mlflow</span></code>.</li>
<li><strong>sample_input</strong> – A sample input used to add the MLeap flavor to the model.
This must be a PySpark DataFrame that the model can evaluate. If
<code class="docutils literal notranslate"><span class="pre">sample_input</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the MLeap flavor is not added.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.ml</span> <span class="k">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.ml.classification</span> <span class="k">import</span> <span class="n">LogisticRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.ml.feature</span> <span class="k">import</span> <span class="n">HashingTF</span><span class="p">,</span> <span class="n">Tokenizer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">training</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">([</span>
<span class="gp">... </span>  <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;a b c d e spark&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
<span class="gp">... </span>  <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;b d&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">),</span>
<span class="gp">... </span>  <span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="s2">&quot;spark f g h&quot;</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
<span class="gp">... </span>  <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="s2">&quot;hadoop mapreduce&quot;</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">)</span> <span class="p">],</span> <span class="p">[</span><span class="s2">&quot;id&quot;</span><span class="p">,</span> <span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="s2">&quot;label&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Tokenizer</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;words&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">hashingTF</span> <span class="o">=</span> <span class="n">HashingTF</span><span class="p">(</span><span class="n">inputCol</span><span class="o">=</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">getOutputCol</span><span class="p">(),</span> <span class="n">outputCol</span><span class="o">=</span><span class="s2">&quot;features&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lr</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">maxIter</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">regParam</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">stages</span><span class="o">=</span><span class="p">[</span><span class="n">tokenizer</span><span class="p">,</span> <span class="n">hashingTF</span><span class="p">,</span> <span class="n">lr</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlflow</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;spark-model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="mlflow.spark.save_model">
<code class="descclassname">mlflow.spark.</code><code class="descname">save_model</code><span class="sig-paren">(</span><em>spark_model</em>, <em>path</em>, <em>mlflow_model=&lt;mlflow.models.Model object&gt;</em>, <em>conda_env=None</em>, <em>dfs_tmpdir=None</em>, <em>sample_input=None</em><span class="sig-paren">)</span><a class="headerlink" href="#mlflow.spark.save_model" title="Permalink to this definition"> </a></dt>
<dd><p>Save a Spark MLlib Model to a local path.</p>
<p>By default, this function saves models using the Spark MLlib persistence mechanism.
Additionally, if a sample input is specified using the <code class="docutils literal notranslate"><span class="pre">sample_input</span></code> parameter, the model
is also serialized in MLeap format and the MLeap flavor is added.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>spark_model</strong> – Spark model to be saved - MLFlow can only save descendants of
pyspark.ml.Model which implement MLReadable and MLWritable.</li>
<li><strong>path</strong> – Local path where the model is to be saved.</li>
<li><strong>mlflow_model</strong> – MLflow model config this flavor is being added to.</li>
<li><strong>conda_env</strong> – <p>Either a dictionary representation of a Conda environment or the path to a
Conda environment yaml file. If provided, this decribes the environment
this model should be run in. At minimum, it should specify the dependencies
contained in <a class="reference internal" href="#mlflow.spark.get_default_conda_env" title="mlflow.spark.get_default_conda_env"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_default_conda_env()</span></code></a>. If <cite>None</cite>, the default
<a class="reference internal" href="#mlflow.spark.get_default_conda_env" title="mlflow.spark.get_default_conda_env"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_default_conda_env()</span></code></a> environment is added to the model.
The following is an <em>example</em> dictionary representation of a Conda
environment:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">&#39;name&#39;</span><span class="p">:</span> <span class="s1">&#39;mlflow-env&#39;</span><span class="p">,</span>
    <span class="s1">&#39;channels&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;defaults&#39;</span><span class="p">],</span>
    <span class="s1">&#39;dependencies&#39;</span><span class="p">:</span> <span class="p">[</span>
        <span class="s1">&#39;python=3.7.0&#39;</span><span class="p">,</span>
        <span class="s1">&#39;pyspark=2.3.0&#39;</span>
    <span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><strong>dfs_tmpdir</strong> – Temporary directory path on Distributed (Hadoop) File System (DFS) or local
filesystem if running in local mode. The model is be written in this
destination and then copied to the requested local path. This is necessary
as Spark ML models read from and write to DFS if running on a cluster. All
temporary files created on the DFS are removed if this operation
completes successfully. Defaults to <code class="docutils literal notranslate"><span class="pre">/tmp/mlflow</span></code>.</li>
<li><strong>sample_input</strong> – A sample input that is used to add the MLeap flavor to the model.
This must be a PySpark DataFrame that the model can evaluate. If
<code class="docutils literal notranslate"><span class="pre">sample_input</span></code> is <code class="docutils literal notranslate"><span class="pre">None</span></code>, the MLeap flavor is not added.</li>
</ul>
</td>
</tr>
</tbody>
</table>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">mlflow</span> <span class="k">import</span> <span class="n">spark</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">pyspark.ml.pipeline.PipelineModel</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1">#your pyspark.ml.pipeline.PipelineModel type</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="o">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mlflow</span><span class="o">.</span><span class="n">spark</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;spark-model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

</div>


              </div>
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="mlflow.sklearn.html" class="btn btn-neutral" title="mlflow.sklearn" accesskey="p"><span class="db-icon db-icon-chevron-left"></span> Previous</a>
      
      
        <a href="mlflow.tensorflow.html" class="btn btn-neutral" title="mlflow.tensorflow" accesskey="n">Next <span class="db-icon db-icon-chevron-right"></span></a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2019. All rights reserved.
      </p>

  </div> 

</footer>
          </div>
        </div>
      </section>
    </main>
  </page>

  


  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT:'../',
      VERSION:'1.1.0',
      COLLAPSE_INDEX:false,
      FILE_SUFFIX:'.html',
      HAS_SOURCE:  true
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/languagesections.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  
  
  
  <script type="text/javascript">var CLIPPY_SVG_PATH = "../_static/clippy.svg";</script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-44077918-9"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-44077918-9');
</script>


  
</body>
</html>